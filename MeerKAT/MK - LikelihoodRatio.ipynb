{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Likelihood Ratio for MeerKAT ##\n",
    "\n",
    "This notebook has the running of the Likelihood Ratio Code on MeerKAT.  Once the output from the Ridgeline Code has been produced this code can be used to determine the list of possible hosts for the MeerKAT data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "from astropy.io import fits\n",
    "from astropy.table import Table\n",
    "import pandas as pd\n",
    "from os.path import exists\n",
    "from sklearn.neighbors import KernelDensity\n",
    "import RidgelineFiles as RLF\n",
    "from ridge_toolkitMK import DefineCutoutHDU, GetAvailableSources, GetCutoutArray\n",
    "from SourceSearchMK import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if exists(RLF.psl) == False:\n",
    "    print('Ridgelines not drawn.  Full Ridgeline code now running. Please wait output will show below.')\n",
    "    %run 'MK - Ridgelines.ipynb'\n",
    "else:\n",
    "    print('Ridgeline information present. Please continue')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TotalFluxCut = str(RLF.TFC)\n",
    "available_sources = GetAvailableSources(TotalFluxCut)\n",
    "print(available_sources.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load in the optical/IR and LOFAR catalogues, form tables and df and save as text files \n",
    "# Check columns esp on the Opt/IR\n",
    "OptTable = TableOfSources(str(RLF.OptCat))\n",
    "LofarTable = TableFromLofar(str(RLF.LofCat))\n",
    "Lofardf = LofarTable.to_pandas()\n",
    "Optdf = OptTable.to_pandas()\n",
    "Optdf.to_csv(RLF.OptCatdf, columns = [str(RLF.IDW), str(RLF.IDP), str(RLF.PossRA), str(RLF.PossDEC), str(RLF.OptMagA), str(RLF.OptMagP)], header = True, index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up source_list to be used in all of the following fuctions/cells\n",
    "probfile = RLF.psl\n",
    "source_list = GetSourceList(available_sources, probfile)\n",
    "#source_list.remove('ILTJ163506.94+602836.1')\n",
    "#source_list.remove('ILTJ092143.70+641518.6')\n",
    "print(len(source_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating cutouts from the pw table so that it is easier to find the magnitudes for the 30 closest\n",
    "# Only needs to be done once\n",
    "for source in source_list:\n",
    "    for asource in available_sources:\n",
    "        if source == asource[0]:\n",
    "            source_name = asource[0]\n",
    "            lofarra = asource[4].astype(float)\n",
    "            lofardec = asource[5].astype(float)\n",
    "            sizepix = asource[6].astype(float)\n",
    "            \n",
    "            size = sizepix * RLF.ddel # convert size in pixels to degrees\n",
    "            subcat = Optdf[(np.abs(Optdf[str(RLF.PossRA)] - lofarra) * np.cos(lofardec * np.pi / 180.0) < size) & (np.abs(Optdf[str(RLF.PossDEC)] - lofardec) < size)].copy()\n",
    "\n",
    "            # Insert the uniform optical position error if required             \n",
    "            \n",
    "            subcat['raErr'] = np.where(np.isnan(subcat[str(RLF.OptMagP)]), RLF.UniWErr, RLF.UniLErr)\n",
    "            subcat['decErr'] = np.where(np.isnan(subcat[str(RLF.OptMagP)]), RLF.UniWErr, RLF.UniLErr)\n",
    "            \n",
    "            subcat.to_csv(RLF.MagCO %source_name, columns = [str(RLF.IDW), str(RLF.IDP), str(RLF.PossRA), str(RLF.PossDEC), 'raErr', 'decErr', str(RLF.OptMagA), str(RLF.OptMagP)], header = True, index = False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Looping through all successful sources to create the cutoutcat .txt files.  The distance away to form\n",
    "# the sub-catalogue is set in RLConstants and is currently set to 1 arcmin RA and 0.5 arcmin DEC.\n",
    "# Only needs to be done once\n",
    "\n",
    "source_count = 0 ## Keeps track of where the loop is\n",
    "for source in source_list:\n",
    "    for asource in available_sources:\n",
    "        if source == asource[0]:\n",
    "            size = asource[6].astype(float)\n",
    "            lofar_ra, lofar_dec = SourceInfo(source, LofarTable)[:2]\n",
    "            #lofar_ra = asource[4].astype(float)\n",
    "            #lofar_dec = asource[5].astype(float)\n",
    "            subcat1 = CreateSubCat(OptTable, lofar_ra, lofar_dec)\n",
    "    \n",
    "            # Insert the uniform optical position error if required\n",
    "            subcatdf = subcat1.to_pandas()\n",
    "\n",
    "            # Insert the uniform optical position error if required             \n",
    "\n",
    "            subcatdf['raErr'] = np.where(np.isnan(subcatdf[str(RLF.OptMagP)]), RLF.UniWErr, RLF.UniLErr)\n",
    "            subcatdf['decErr'] = np.where(np.isnan(subcatdf[str(RLF.OptMagP)]), RLF.UniWErr, RLF.UniLErr)\n",
    "            subcat2 = Table.from_pandas(subcatdf)\n",
    "    \n",
    "            cutoutcat = CreateCutOutCat(source, LofarTable, subcat2, lofar_ra, lofar_dec, size)\n",
    "            source_count += 1\n",
    "            print('Source Number = ' + str(source_count))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a table of R distance information from LOFAR Catalogue position\n",
    "# Only needs to be done once\n",
    "for source in source_list:\n",
    "    CreateLDistTable(source, available_sources)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the 30 closest sources for each ridgeline\n",
    "# Only needs to be done once\n",
    "n = 30\n",
    "NClosestDistances(source_list, available_sources, LofarTable, n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generating the likelihood ratios for all possible close sources, for each drawn\n",
    "# ridgeline, using the R distance from LOFAR Catalogue position and the ridgeline.\n",
    "# Only needs to be done once\n",
    "LikelihoodRatios(source_list, available_sources)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load in the three text files for each source, join all the table information together and save\n",
    "# Only needs to be done once\n",
    "\n",
    "for source in source_list:\n",
    "\n",
    "    LofarLR = pd.read_csv(RLF.NLLR %source, header = 0)\n",
    "    RidgeLR = pd.read_csv(RLF.NRLR %source, header = 0, usecols = ['Ridge_LR'])\n",
    "    MagCutOut = pd.read_csv(RLF.MagCO %source, header = 0, usecols = [str(RLF.IDW), str(RLF.IDP), str(RLF.PossRA), str(RLF.OptMagA), str(RLF.OptMagP)])\n",
    "    MagCutOut[str(RLF.PossRA)] = MagCutOut[str(RLF.PossRA)].apply(lambda x: round(x, 7))\n",
    "            \n",
    "    All_LR = LofarLR.join(RidgeLR['Ridge_LR'])\n",
    "    All_LR['Multi_LR'] = All_LR['Lofar_LR'].astype(np.float64).multiply(All_LR['Ridge_LR'].astype(np.float64), axis = 'index')\n",
    "        \n",
    "    All_LR.columns=['LofarRDis', 'Lofar_LR', str(RLF.PossRA), str(RLF.PossDEC), 'Ridge_LR', 'Multi_LR']\n",
    "    All_LR[str(RLF.PossRA)] = All_LR[str(RLF.PossRA)].apply(lambda x: round(x, 7))\n",
    "            \n",
    "    MagLR = All_LR.merge(MagCutOut, on = str(RLF.PossRA))\n",
    "            \n",
    "    MagLR.to_csv(RLF.NLRI %source, columns = ['LofarRDis', 'Lofar_LR', str(RLF.PossRA), str(RLF.PossDEC), 'Ridge_LR', 'Multi_LR', str(RLF.IDW), str(RLF.IDP), str(RLF.OptMagP), str(RLF.OptMagA)], header = True, index = False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Functions I need to calculate the magnitude LR\n",
    "# Make sure that the RA and DEC in RidgelineFiles has been changed to match the sky area being used\n",
    "area = (np.deg2rad(RLF.LRAu) - np.deg2rad(RLF.LRAd)) * (np.sin(np.deg2rad(RLF.LDECu)) - np.sin(np.deg2rad(RLF.LDECd))) * np.rad2deg(3600)**2 \n",
    "\n",
    "def get_nm(m, binscen, nm):\n",
    "    find_nm = np.interp(m, binscen, nm)\n",
    "    return find_nm\n",
    "\n",
    "def get_qm(m, binscen, qm):\n",
    "    find_qm = np.interp(m, binscen, qm)\n",
    "    return find_qm\n",
    "\n",
    "def get_LR(m, fr, binsn, binsq, nm, qm):\n",
    "    n = get_nm(m, binsn, nm)\n",
    "    q = get_qm(m, binsq, qm)\n",
    "    LR = (q * fr) / n\n",
    "    return LR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up the KDE for n(m) and q(m)\n",
    "\n",
    "rbins = np.linspace(12, 30, 361)\n",
    "rbinscen = (rbins[:-1] + rbins[1:]) / 2\n",
    "W1bins = np.linspace(10, 23, 261)\n",
    "W1binscen = (W1bins[:-1] + W1bins[1:]) / 2\n",
    "\n",
    "# Form the separate band catalogues from DR2 to form the KDE for n(m)\n",
    "Optdfr = Optdf[~np.isnan(Optdf[str(RLF.OptMagP)])]\n",
    "Optdfw = Optdf[~np.isnan(Optdf[str(RLF.OptMagA)])]\n",
    "Optdfr.reset_index(drop = True, inplace = True)  # Might not be needed but I have done it anyway\n",
    "Optdfw.reset_index(drop = True, inplace = True)  # Might not be needed but I have done it anyway\n",
    "kde_nmw1 = KernelDensity(kernel = 'gaussian', bandwidth = RLF.bw)\n",
    "kde_nmw1.fit(np.array(Optdfw)[str(RLF.OptMagA)][:, None])\n",
    "kde_nmr = KernelDensity(kernel = 'gaussian', bandwidth = RLF.bw)\n",
    "kde_nmr.fit(np.array(Optdfr)[str(RLF.OptMagP)][:, None])\n",
    "\n",
    "# Load in my host data to form the KDE for q(m)\n",
    "\n",
    "hdata = pd.read_csv(str(RLF.DR1Hosts), header = 0, usecols = ['W1mag', 'i'])\n",
    "hdata['r'] = hdata['i'].apply(lambda y: y + 0.33)\n",
    "kde_hw1 = KernelDensity(kernel = 'gaussian', bandwidth = RLF.bw)\n",
    "kde_hw1.fit(np.array(hdata)['W1mag'][:, None])\n",
    "kde_hr = KernelDensity(kernel = 'gaussian', bandwidth = RLF.bw)\n",
    "kde_hr.fit(np.array(hdata)['r'][:, None])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Then calculate the LR using the distance from the text files and save to text files\n",
    "\n",
    "prob_qmhw1 = np.exp(kde_hw1.score_samples(np.array(W1binscen)[:, None]))\n",
    "q_mhw1 = prob_qmhw1 * len(hdata['W1mag'])/np.sum(prob_qmhw1)\n",
    "prob_nmw1 = np.exp(kde_nmw1.score_samples(W1binscen[:, None]))\n",
    "n_mw1 = prob_nmw1/area * len(Optdfw[str(RLF.OptMagA)])/np.sum(prob_nmw1)\n",
    "\n",
    "prob_qmhr = np.exp(kde_hr.score_samples(np.array(rbinscen)[:, None]))\n",
    "q_mhr = prob_qmhr * len(hdata['r'])/np.sum(prob_qmhr)\n",
    "prob_nmr = np.exp(kde_nmr.score_samples(rbinscen[:, None]))\n",
    "n_mr = prob_nmr/area * len(Optdfr[str(RLF.OptMagP)])/np.sum(prob_nmr)\n",
    "\n",
    "for source in source_list:\n",
    "            \n",
    "    MLR = pd.read_csv(RLF.NLRI %source, header = 0, usecols = ['LofarRDis', str(RLF.PossRA), str(RLF.PossDEC), str(RLF.IDW), str(RLF.IDP), str(RLF.OptMagP), str(RLF.OptMagA), 'Multi_LR'])\n",
    "    MLR[str(RLF.LRMA)] = MLR.apply(lambda row: get_LR(np.float128(row[str(RLF.OptMagA)]), np.float128(row['Multi_LR']), W1binscen, W1binscen, n_mw1, q_mhw1), axis = 1).astype(np.float128)\n",
    "    MLR[str(RLF.LRMP)] = MLR.apply(lambda row: get_LR(np.float128(row[str(RLF.OptMagP)]), np.float128(row['Multi_LR']), rbinscen, rbinscen, n_mr, q_mhr), axis = 1).astype(np.float128)\n",
    "\n",
    "    MLR[str(RLF.LRMC)] = MLR[str(RLF.LRMA)].astype(np.float64).multiply(MLR[str(RLF.LRMP)].astype(np.float64), axis = 'index')\n",
    "    \n",
    "    MLR.to_csv(RLF.MLR %source, columns = ['LofarRDis', str(RLF.PossRA), str(RLF.PossDEC), str(RLF.IDW), str(RLF.IDP), str(RLF.OptMagP), str(RLF.OptMagA), str(RLF.LRMA), str(RLF.LRMP), str(RLF.LRMC)], header = True, index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For each source in the list find the maximum combined LR and store all the information\n",
    "\n",
    "def FindMax(source):\n",
    "    info = pd.read_csv(RLF.MLR %source, header = 0, usecols = [str(RLF.PossRA), str(RLF.PossDEC), str(RLF.IDW), str(RLF.IDP), str(RLF.LRMC)])\n",
    "    info[str(RLF.IDW)] = info[str(RLF.IDW)].map(lambda x: x.strip('b').strip(\"''\"))\n",
    "    info[str(RLF.IDP)] = info[str(RLF.IDP)].map(lambda x: x.strip('b').strip(\"''\"))\n",
    "    #info[str(RLF.ID3)] = info[str(RLF.ID3)].map(lambda x: x.strip('b').strip(\"''\"))\n",
    "    CP = info.loc[info[str(RLF.LRMC)].idxmax()].copy()\n",
    "    CP['PossFail'] = np.where(CP[str(RLF.LRMC)] == 0, 1, 0)\n",
    "    CP[str(RLF.LSN)] = source\n",
    "    \n",
    "    return CP\n",
    "\n",
    "PossHosts = pd.concat([FindMax(source) for source in source_list], ignore_index = True, axis = 1)\n",
    "PossHosts.columns = PossHosts.loc[str(RLF.LSN)]\n",
    "PossHosts = PossHosts.drop(index = [str(RLF.LRMC), str(RLF.LSN)])\n",
    "PossHostsT = PossHosts.transpose()\n",
    "PossHostsT.to_csv(RLF.PossHosts, header = True, index = True)#,  columns = [str(RLF.LSN), str(RLF.PossRA), str(RLF.PossDEC), str(RLF.IDW), str(RLF.IDP), str(RLF.ID3), str(RLF.OptMagP), str(RLF.OptMagA)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of sources with a 0 max LR and therefore would possibly be a failed LR\n",
    "# or defined by being closest to LOFAR\n",
    "print(np.sum(PossHostsT['PossFail']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
