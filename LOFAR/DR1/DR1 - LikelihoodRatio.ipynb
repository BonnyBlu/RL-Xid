{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Likelihood Ratio for DR1 ##\n",
    "\n",
    "This notebook has the running of the Likelihood Ratio Code on DR1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "from astropy.io import fits\n",
    "from astropy.table import Table\n",
    "import pandas as pd\n",
    "from os.path import exists\n",
    "from sklearn.neighbors import KernelDensity\n",
    "import RidgelineFilesDR1 as RLF\n",
    "from ridge_toolkitDR1 import DefineCutoutHDU, GetAvailableSources, GetCutoutArray\n",
    "from SourceSearchDR1 import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "if exists(RLF.psl) == False:\n",
    "    print('Ridgelines not drawn.  Full Ridgeline code now running. Please wait output will show below.')\n",
    "    %run 'DR1 - Ridgelines.ipynb'\n",
    "else:\n",
    "    print('Ridgeline information present. Please continue')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3946, 14)\n"
     ]
    }
   ],
   "source": [
    "TotalFluxCut = str(RLF.TFC)\n",
    "available_sources = GetAvailableSources(TotalFluxCut)\n",
    "print(available_sources.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3384\n"
     ]
    }
   ],
   "source": [
    "# Set up source_list to be used in all of the following fuctions/cells\n",
    "probfile = RLF.psl\n",
    "source_list = GetSourceList(available_sources, probfile)\n",
    "#np.savetxt('Catalogue/DR1/source_listDR1Full.csv', source_list, delimiter = ',', fmt='%s', encoding = 'utf-8')\n",
    "print(len(source_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# Load in the optical/IR and LOFAR catalogues, form tables and df and save as text files \n",
    "# Check columns esp on the Opt/IR\n",
    "# Do not need to run if OptCatdf exists, Yes I do CreateSubCat needs them\n",
    "OptTable = TableOfSources(str(RLF.OptCat))\n",
    "Optdf = OptTable.to_pandas()\n",
    "Optdf.to_csv(RLF.OptCatdf, columns = [str(RLF.IDW), str(RLF.IDP), str(RLF.PossRA), str(RLF.PossDEC), str(RLF.OptMagA), str(RLF.MagAErr), str(RLF.OptMagP), str(RLF.MagPErr)], header = True, index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "LofarTable = TableFromLofar(str(RLF.LofCat))\n",
    "Lofardf = LofarTable.to_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# Creating cutouts from the pw table so that it is easier to find the magnitudes for the 30 closest\n",
    "# Only needs to be done once\n",
    "for source in source_list:\n",
    "    for asource in available_sources:\n",
    "        if source == asource[0]:\n",
    "            source_name = asource[0]\n",
    "            lofarra = asource[4].astype(float)\n",
    "            lofardec = asource[5].astype(float)\n",
    "            sizepix = asource[6].astype(float)\n",
    "            \n",
    "            size = sizepix * RLC.ddel # convert size in pixels to degrees\n",
    "            subcat = Optdf[(np.abs(Optdf[str(RLF.PossRA)] - lofarra) * np.cos(lofardec * np.pi / 180.0) < size) & (np.abs(Optdf[str(RLF.PossDEC)] - lofardec) < size)].copy()\n",
    "\n",
    "            # Insert the uniform optical position error if required             \n",
    "            \n",
    "            #subcat['raErr'] = np.where(np.isnan(subcat[str(RLF.OptMagP)]), RLF.UniWErr, RLF.UniLErr)\n",
    "            #subcat['decErr'] = np.where(np.isnan(subcat[str(RLF.OptMagP)]), RLF.UniWErr, RLF.UniLErr)\n",
    "            \n",
    "            subcat.to_csv(RLF.MagCO %source_name, columns = [str(RLF.IDW), str(RLF.IDP), str(RLF.PossRA), str(RLF.PossDEC), 'raErr', 'decErr', str(RLF.OptMagA), str(RLF.OptMagP)], header = True, index = False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# Looping through all successful sources to create the cutoutcat .txt files.  The distance away to form\n",
    "# the sub-catalogue is set in RLConstants and is currently set to 1 arcmin RA and 0.5 arcmin DEC.\n",
    "# Only needs to be done once\n",
    "\n",
    "source_count = 0 ## Keeps track of where the loop is\n",
    "for source in source_list:\n",
    "    for asource in available_sources:\n",
    "        if source == asource[0]:\n",
    "            size = asource[6].astype(float)\n",
    "            lofar_ra, lofar_dec = SourceInfo(source, LofarTable)[:2]\n",
    "            #lofar_ra = asource[4].astype(float)\n",
    "            #lofar_dec = asource[5].astype(float)\n",
    "            subcat1 = CreateSubCat(OptTable, lofar_ra, lofar_dec)\n",
    "    \n",
    "            # Insert the uniform optical position error if required\n",
    "            #subcatdf = subcat1.to_pandas()\n",
    "\n",
    "            # Insert the uniform optical position error if required             \n",
    "\n",
    "            #subcatdf['raErr'] = np.where(np.isnan(subcatdf[str(RLF.OptMagP)]), RLF.UniWErr, RLF.UniLErr)\n",
    "            #subcatdf['decErr'] = np.where(np.isnan(subcatdf[str(RLF.OptMagP)]), RLF.UniWErr, RLF.UniLErr)\n",
    "            #subcat2 = Table.from_pandas(subcatdf)\n",
    "    \n",
    "            cutoutcat = CreateCutOutCat(source, LofarTable, subcat1)\n",
    "            source_count += 1\n",
    "            #print('Source Number = ' + str(source_count))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# Create a table of positional data for hosts\n",
    "positions = CreatePositionTable(source_list, available_sources, LofarTable)\n",
    "positions.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# NEEDS TO BE A FUNCTION\n",
    "# Generates the Host magnitude information\n",
    "pwfulldf = pd.read_csv(RLF.OptCatdf, header = 0, usecols = ['AllWISE', 'i', 'W1mag'])\n",
    "pos = pd.read_csv(str(RLF.Position), header = 0, usecols = ['Source_Name', 'AllWISE', 'Host_RA', 'Host_DEC', 'Host_RA_errOpt', 'Host_DEC_errOpt', 'LOFAR_RA_errRad', 'LOFAR_DEC_errRad'])\n",
    "pwfulldf['AllWISE'] = pwfulldf['AllWISE'].map(lambda x: x.strip('b').strip(\"''\"))\n",
    "pos['AllWISE'] = pos['AllWISE'].map(lambda x: x.strip('b').strip(\"''\"))\n",
    "\n",
    "mag = pos.merge(pwfulldf, on = 'AllWISE')\n",
    "\n",
    "mag['Source_Name'] = mag['Source_Name'].map(lambda x: x.strip('b').strip(\"''\"))\n",
    "mag.to_csv(str(RLF.DR1Hosts), columns = [ 'Source_Name', 'AllWISE', 'Host_RA', 'Host_DEC', 'LOFAR_RA_errRad', 'LOFAR_DEC_errRad', 'Host_RA_errOpt', 'Host_DEC_errOpt', 'W1mag', 'i'], header = True, index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a table of R distance information from LOFAR Catalogue position\n",
    "# Only needs to be done once\n",
    "for source in source_list:\n",
    "    CreateRDistTable(source, available_sources)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the 30 closest sources for each ridgeline\n",
    "# Only needs to be done once\n",
    "n = 30\n",
    "NClosestDistances(source_list, available_sources, LofarTable, n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generating the likelihood ratios for all possible close sources, for each drawn\n",
    "# ridgeline, using the R distance from LOFAR Catalogue position and the ridgeline.\n",
    "# Only needs to be done once\n",
    "LikelihoodRatios(source_list, available_sources)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CREATE NEAREST 30 INFO\n",
    "# Load in the three text files for each source, join all the table information together and save\n",
    "# Only needs to be done once\n",
    "\n",
    "for source in source_list:\n",
    "\n",
    "    LofarLR = pd.read_csv(RLF.LLR %source, header = 0)\n",
    "    RidgeLR = pd.read_csv(RLF.RLR %source, header = 0, usecols = ['Ridge_LR'])\n",
    "    MagCutOut = pd.read_csv(RLF.MagCO %source, header = 0, usecols = [str(RLF.IDW), str(RLF.IDP), str(RLF.PossRA), str(RLF.OptMagA), str(RLF.OptMagP)])\n",
    "    MagCutOut[str(RLF.PossRA)] = MagCutOut[str(RLF.PossRA)].apply(lambda x: round(x, 7))\n",
    "    MCO = MagCutOut.drop(columns = ['AllWISE'])\n",
    "            \n",
    "    All_LR = LofarLR.join(RidgeLR['Ridge_LR'])\n",
    "    All_LR['Multi_LR'] = np.where(~np.isnan(All_LR['Ridge_LR']), All_LR['Lofar_LR'].astype(np.float64).multiply(All_LR['Ridge_LR'].astype(np.float64), axis = 'index'), All_LR['Lofar_LR'].astype(np.float64))\n",
    "        \n",
    "    All_LR.columns=['AllWISE', 'LofarRDis', 'Lofar_LR', str(RLF.PossRA), str(RLF.PossDEC), 'Ridge_LR', 'Multi_LR']\n",
    "    All_LR[str(RLF.PossRA)] = All_LR[str(RLF.PossRA)].apply(lambda x: round(x, 7))\n",
    "            \n",
    "    MagLR = All_LR.merge(MCO, on = str(RLF.PossRA))\n",
    "            \n",
    "    MagLR.to_csv(RLF.LRI %source, columns = ['AllWISE', 'LofarRDis', 'Lofar_LR', str(RLF.PossRA), str(RLF.PossDEC), 'Ridge_LR', 'Multi_LR', str(RLF.IDW), str(RLF.IDP), str(RLF.OptMagP), str(RLF.OptMagA)], header = True, index = False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load in Host Info\n",
    "Hosts = pd.read_csv(str(RLF.DR1HostsFull), usecols = [ 'Source_Name', 'AllWISE', 'Host_RA', 'Host_DEC', 'W1mag', 'i'], header = 0)\n",
    "Hosts['Colour'] = Hosts['i'].astype(np.float64).subtract(Hosts['W1mag'].astype(np.float64), axis = 'index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the colour column and sample the df\n",
    "pwfulldf = pd.read_csv(RLF.OptCatdf, header = 0, usecols = ['AllWISE', 'i', 'W1mag'])\n",
    "ColourPW = pwfulldf[~np.isnan(pwfulldf['i']) & ~np.isnan(pwfulldf['W1mag'])].copy()\n",
    "ColourPW.reset_index(drop = True, inplace = True)\n",
    "\n",
    "ColourPW['Colour'] = ColourPW['i'].subtract(ColourPW['W1mag'], axis = 'index')\n",
    "ColSam = ColourPW.sample(50000, replace = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Skyarea Covered byt he LOFAR data set\n",
    "area = (np.deg2rad(RLC.LRAu) - np.deg2rad(RLC.LRAd)) * (np.sin(np.deg2rad(RLC.LDECu)) - np.sin(np.deg2rad(RLC.LDECd))) * np.rad2deg(3600)**2\n",
    "print(area)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Not running on i-band so only need the W1 band cells\n",
    "hh, ww1 = np.mgrid[Hosts['Colour'].min() : Hosts['Colour'].max() : 0.05, Hosts['W1mag'].min() : Hosts['W1mag'].max() : 0.05]\n",
    "h_sample = np.vstack([ww1.ravel(), hh.ravel()]).T\n",
    "h_train = np.vstack([Hosts['W1mag'], Hosts['Colour']]).T\n",
    "kde_h = KernelDensity(kernel = 'gaussian', bandwidth = RLC.bw)\n",
    "kde_h.fit(h_train)\n",
    "prob_h = np.exp(kde_h.score_samples(h_sample))\n",
    "norm_h = len(Hosts['W1mag'])/np.sum(prob_h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "oo, ww2 = np.mgrid[ColSam['Colour'].min() : ColSam['Colour'].max() : 0.05, ColSam['W1mag'].min() : ColSam['W1mag'].max() : 0.05]\n",
    "o_sample = np.vstack([ww2.ravel(), oo.ravel()]).T\n",
    "o_train = np.vstack([ColSam['W1mag'], ColSam['Colour']]).T\n",
    "kde_o = KernelDensity(kernel = 'gaussian', bandwidth = RLC.bw)\n",
    "kde_o.fit(o_train)\n",
    "prob_o = np.exp(kde_o.score_samples(o_sample))\n",
    "norm_o = len(ColSam['W1mag'])/np.sum(prob_o) * area"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# functions needed\n",
    "\n",
    "def GetLR(fr, qm, nm):\n",
    "    lr = (fr * qm) / nm\n",
    "    return lr\n",
    "\n",
    "def Getqmc(m, c):\n",
    "    qmc = np.exp(kde_h.score_samples(np.array([m, c]).reshape(1, -1)))\n",
    "    return qmc * norm_h\n",
    "\n",
    "def Getnmc(m, c):\n",
    "    nmc = np.exp(kde_o.score_samples(np.array([m, c]).reshape(1, -1)))\n",
    "    return nmc * norm_o"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculating the LR from the text files for the W1 band hosts\n",
    "\n",
    "for source in source_list:\n",
    "            \n",
    "    #MLRhw = pd.read_csv(str(RLF.NLRI) %source, header = 0, usecols = ['AllWise', 'LofarRDis', 'ra', 'dec', 'Lofar_LR', 'Ridge_LR', 'SBLR', 'Multi_LR',  'i', 'W1mag'])\n",
    "    MLR = pd.read_csv(str(RLF.LRI) %source, header = 0, usecols = ['AllWISE', 'LofarRDis', 'ra', 'dec', 'Lofar_LR', 'Ridge_LR', 'Multi_LR',  'i', 'W1mag'])\n",
    "    MLR['Colour'] = MLR['i'].subtract(MLR['W1mag'], axis = 'index')\n",
    "    MCLR = MLR[~np.isnan(MLR['Colour'])].copy()\n",
    "    MCLR['MCLLR'] = MCLR.apply(lambda row: GetLR(row['Lofar_LR'], Getqmc(row['W1mag'], row['Colour']), Getnmc(row['W1mag'], row['Colour'])), axis = 1).astype(np.float128)\n",
    "    MCLR['MCRLR'] = MCLR.apply(lambda row: GetLR(row['Ridge_LR'], Getqmc(row['W1mag'], row['Colour']), Getnmc(row['W1mag'], row['Colour'])), axis = 1).astype(np.float128)\n",
    "    #MCLRhw['MCSBLR'] = MCLRhw.apply(lambda row: GetLR(row['SBLR'], Getqmcw(row['W1mag'], row['Colour']), Getnmcw(row['W1mag'], row['Colour'])), axis = 1).astype(np.float128)\n",
    "    MCLR['MCMLR'] = MCLR.apply(lambda row: GetLR(row['Multi_LR'], Getqmc(row['W1mag'], row['Colour']), Getnmc(row['W1mag'], row['Colour'])), axis = 1).astype(np.float128)\n",
    "            \n",
    "    #MCLRhw.to_csv(str(RLF.MCLR) %source, columns = ['AllWise', 'LofarRDis', 'ra', 'dec', 'Lofar_LR', 'Ridge_LR', 'SBLR', 'Multi_LR',  'i', 'W1mag', 'MCLLR', 'MCRLR', 'MCSBLR', 'MCMLR'], header = True, index = False)\n",
    "    MCLR.to_csv(str(RLF.LR) %source, columns = ['AllWISE', 'LofarRDis', 'ra', 'dec', 'Lofar_LR', 'Ridge_LR', 'Multi_LR',  'i', 'W1mag', 'MCLLR', 'MCRLR', 'MCMLR'], header = True, index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the max LR in each column and then count up how many correct hosts found using the KDE method for the i band\n",
    "\n",
    "Sources = pd.read_csv(str(RLF.Position), header = None, usecols = [0, 1], names = ['Source_Name', 'AllWISE'])\n",
    "Sources['Source_Name'] = Sources['Source_Name'].map(lambda x: x.strip('b').strip(\"''\"))\n",
    "Sources['AllWISE'] = Sources['AllWISE'].map(lambda x: x.strip('b').strip(\"''\"))\n",
    "Lofar_tot = 0\n",
    "Ridge_tot = 0\n",
    "Either_tot = 0\n",
    "Multi_tot = 0\n",
    "Successful = []\n",
    "odd = []\n",
    "LC = 0\n",
    "RC = 0\n",
    "LRC = 0\n",
    "NC = 0\n",
    "MLRC = 0\n",
    "\n",
    "for source in source_list:\n",
    "\n",
    "    #MCLRhw = pd.read_csv(str(RLF.MCLR) %source, header = 0, usecols = ['AllWise', 'LofarRDis', 'ra', 'dec', 'Lofar_LR', 'Ridge_LR', 'SBLR', 'Multi_LR',  'i', 'W1mag', 'MCLLR', 'MCRLR', 'MCSBLR', 'MCMLR'])\n",
    "    MCLR = pd.read_csv(str(RLF.LR) %source, header = 0, usecols = ['AllWISE', 'LofarRDis', 'ra', 'dec', 'Lofar_LR', 'Ridge_LR', 'Multi_LR',  'i', 'W1mag', 'MCLLR', 'MCRLR', 'MCMLR'])\n",
    "    MCLR['AllWISE'] = MCLR['AllWISE'].map(lambda x: x.strip('b').strip(\"''\"))\n",
    "            \n",
    "    MaxLofarLR = MCLR.loc[MCLR['MCLLR'].idxmax()][0]\n",
    "    MaxRidgeLR = MCLR.loc[MCLR['MCRLR'].idxmax()][0]\n",
    "    #MaxSBLRhw = MCLRhw.loc[MCLRhw['MCSBLR'].idxmax()][0]\n",
    "    MaxMultiLR = MCLR.loc[MCLR['MCMLR'].idxmax()][0]\n",
    "\n",
    "    Sources['Lofar_Count'] = Sources['AllWISE'].apply(lambda x: 1 if x == MaxLofarLR else 0)\n",
    "    Sources['Ridge_Count'] = Sources['AllWISE'].apply(lambda x: 1 if x == MaxRidgeLR else 0)\n",
    "    #Sources['Surface_Count'] = Sources['AllWISE'].apply(lambda x: 1 if x == MaxSBLRhw else 0)\n",
    "    Sources['Multi_Count'] = Sources['AllWISE'].apply(lambda x: 1 if x == MaxMultiLR else 0)\n",
    "            \n",
    "    Lofar_tot += Sources['Lofar_Count'].sum()\n",
    "    Ridge_tot += Sources['Ridge_Count'].sum()\n",
    "    #Surface_tot += Sources['Surface_Count'].sum()\n",
    "    Multi_tot += Sources['Multi_Count'].sum()\n",
    "    \n",
    "    if Sources['Multi_Count'].sum() > 0:\n",
    "        aw = (Sources['AllWISE'].loc[Sources['Multi_Count'] == 1]).values[0]\n",
    "        sn = (Sources['Source_Name'].loc[Sources['AllWISE'] == aw]).values[0]\n",
    "        if sn == source:\n",
    "            Successful.append(str(sn))\n",
    "        else:\n",
    "            print('sn = ' + str(sn))\n",
    "            print('source = ' + str(source))\n",
    "            odd.append(sn) ## It has found a host but the wrong one so not considered a success\n",
    "\n",
    "    \n",
    "    if Sources['Lofar_Count'].sum() > 0 or Sources['Ridge_Count'].sum() > 0:\n",
    "        Either_tot += 1\n",
    "        \n",
    "    if (Sources['Lofar_Count'].sum() > 0 and Sources['Ridge_Count'].sum() > 0) and Sources['Multi_Count'].sum() > 0:\n",
    "        MLRC += 1\n",
    "        \n",
    "    if Sources['Lofar_Count'].sum() > 0 and Sources['Ridge_Count'].sum() > 0:\n",
    "        LRC +=1\n",
    "    elif Sources['Ridge_Count'].sum() > 0 and Sources['Lofar_Count'].sum() == 0:\n",
    "        RC += 1\n",
    "    elif Sources['Lofar_Count'].sum() > 0 and Sources['Ridge_Count'].sum() == 0:\n",
    "        LC += 1\n",
    "    else:\n",
    "        NC += 1\n",
    "\n",
    "print('LRC = ', LRC, 'RC = ', RC, 'LC = ', LC, 'NC = ', NC, 'MLRC = ', MLRC)\n",
    "print(odd)\n",
    "NoHosts = source_list.copy()\n",
    "Fails = [j for j in NoHosts if j not in Successful]\n",
    "print('Number of Successfuls = ' + str(len(Successful)))\n",
    "print('Numbers of Fails = ' + str(len(Fails)))\n",
    "    \n",
    "np.savetxt('Catalogue/SuccessfulDR1Full.csv', Successful, fmt='%s', encoding = 'utf-8', delimiter = ',')\n",
    "np.savetxt('Catalogue/FailsDR1Full.csv', Fails, fmt='%s', encoding = 'utf-8', delimiter = ',')\n",
    "print('Number of correctly found hosts with the Lofar Distance using W1 band =', Lofar_tot - len(odd))\n",
    "print('Number of correctly found hosts with the Ridge Distance using W1 band =', Ridge_tot - len(odd))\n",
    "print('Number of correctly found hosts with the Multiplied Distance using W1 band =', Multi_tot)\n",
    "print('Number of correctly found hosts with the Either Distance using W1 band =', Either_tot - len(odd))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib_venn import venn2, venn2_unweighted\n",
    "import matplotlib.pyplot as plt\n",
    "Lc = LC - LRC\n",
    "Rc = RC - LRC\n",
    "\n",
    "vL = venn2_unweighted(subsets = (LC, RC, LRC), set_labels = ('Lofar', 'Ridge'), set_colors = ('purple', 'skyblue'))\n",
    "plt.gca().set_facecolor('white')\n",
    "plt.gca().set_axis_on()\n",
    "plt.title('Correctly Found Hosts Using Each Separation')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
