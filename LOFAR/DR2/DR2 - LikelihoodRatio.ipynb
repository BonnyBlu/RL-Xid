{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Likelihood Ratio for DR2 ##\n",
    "\n",
    "This notebook has the running of the Likelihood Ratio Code on DR2.  Once the output from the Ridgeline Code has been produced this code can be used to determine the list of possible hosts for the DR2 data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "from astropy.io import fits\n",
    "from astropy.table import Table\n",
    "import pandas as pd\n",
    "from os.path import exists\n",
    "from sklearn.neighbors import KernelDensity\n",
    "import RidgelineFilesDR2 as RLF\n",
    "from ridge_toolkitDR2 import DefineCutoutHDU, GetAvailableSources, GetCutoutArray\n",
    "from SourceSearchDR2 import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This will need the file name chnaging to the script file of the Ridgeline code\n",
    "if exists(RLF.psl) == False:\n",
    "    print('Ridgelines not drawn.  Full Ridgeline code now running. Please wait output will show below.')\n",
    "    %run 'DR2 - Ridgelines.ipynb'\n",
    "else:\n",
    "    print('Ridgeline information present. Please continue')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TotalFluxCut = str(RLF.TFC)\n",
    "available_sources = GetAvailableSources(TotalFluxCut)\n",
    "print(available_sources.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load in the optical/IR and LOFAR catalogues, form tables and df and save as text files \n",
    "# Check columns esp on the Opt/IR\n",
    "OptTable = TableOfSources(str(RLF.OptCat))\n",
    "LofarTable = TableFromLofar(str(RLF.LofCat))\n",
    "Lofardf = LofarTable.to_pandas()\n",
    "Optdf = OptTable.to_pandas()\n",
    "Optdf.to_csv(RLF.OptCatdf, columns = [str(RLF.IDW), str(RLF.IDP), str(RLF.PossRA), str(RLF.PossDEC), str(RLF.OptMagA), str(RLF.OptMagP)], header = True, index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up source_list to be used in all of the following fuctions/cells\n",
    "probfile = RLF.psl\n",
    "source_list = GetSourceList(available_sources, probfile)\n",
    "print('Number of viable sources = ' + len(source_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating cutouts from the pw table so that it is easier to find the magnitudes for the 30 closest\n",
    "# Only needs to be done once\n",
    "for source in source_list:\n",
    "    for asource in available_sources:\n",
    "        if source == asource[0]:\n",
    "            source_name = asource[0]\n",
    "            lofarra = asource[4].astype(float)\n",
    "            lofardec = asource[5].astype(float)\n",
    "            sizepix = asource[6].astype(float)\n",
    "            \n",
    "            size = sizepix * RLF.ddel # convert size in pixels to degrees\n",
    "            subcat = Optdf[(np.abs(Optdf[str(RLF.PossRA)] - lofarra) * np.cos(lofardec * np.pi / 180.0) < size) & (np.abs(Optdf[str(RLF.PossDEC)] - lofardec) < size)].copy()\n",
    "\n",
    "            # Insert the uniform optical position error if required             \n",
    "            \n",
    "            subcat['raErr'] = np.where(np.isnan(subcat[str(RLF.OptMagP)]), RLF.UniWErr, RLF.UniLErr)\n",
    "            subcat['decErr'] = np.where(np.isnan(subcat[str(RLF.OptMagP)]), RLF.UniWErr, RLF.UniLErr)\n",
    "            \n",
    "            subcat.to_csv(RLF.MagCO %source_name, columns = [str(RLF.IDW), str(RLF.IDP), str(RLF.PossRA), str(RLF.PossDEC), 'raErr', 'decErr', str(RLF.OptMagA), str(RLF.OptMagP)], header = True, index = False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Looping through all successful sources to create the cutoutcat .txt files.  The distance away to form\n",
    "# the sub-catalogue is set in RLConstants and is currently set to 1 arcmin RA and 0.5 arcmin DEC.\n",
    "# Only needs to be done once\n",
    "\n",
    "source_count = 0 ## Keeps track of where the loop is\n",
    "for source in source_list:\n",
    "    for asource in available_sources:\n",
    "        if source == asource[0]:\n",
    "            size = asource[6].astype(float)\n",
    "            lofar_ra, lofar_dec = SourceInfo(source, LofarTable)[:2]\n",
    "            #lofar_ra = asource[4].astype(float)\n",
    "            #lofar_dec = asource[5].astype(float)\n",
    "            subcat1 = CreateSubCat(OptTable, lofar_ra, lofar_dec)\n",
    "    \n",
    "            # Insert the uniform optical position error if required\n",
    "            subcatdf = subcat1.to_pandas()\n",
    "\n",
    "            # Insert the uniform optical position error if required             \n",
    "\n",
    "            subcatdf['raErr'] = np.where(np.isnan(subcatdf[str(RLF.OptMagP)]), RLF.UniWErr, RLF.UniLErr)\n",
    "            subcatdf['decErr'] = np.where(np.isnan(subcatdf[str(RLF.OptMagP)]), RLF.UniWErr, RLF.UniLErr)\n",
    "            subcat2 = Table.from_pandas(subcatdf)\n",
    "    \n",
    "            cutoutcat = CreateCutOutCat(source, LofarTable, subcat2, lofar_ra, lofar_dec, size)\n",
    "            source_count += 1\n",
    "            print('Source Number = ' + str(source_count))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a table of R distance information from LOFAR Catalogue position\n",
    "# Only needs to be done once\n",
    "for source in source_list:\n",
    "    CreateLDistTable(source, available_sources)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the 30 closest sources for each ridgeline\n",
    "# Only needs to be done once\n",
    "n = 30\n",
    "NClosestDistances(source_list, available_sources, LofarTable, n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generating the likelihood ratios for all possible close sources, for each drawn\n",
    "# ridgeline, using the R distance from LOFAR Catalogue position and the ridgeline.\n",
    "# Only needs to be done once\n",
    "GetFr(source_list, available_sources)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CREATE NEAREST 30 INFO\n",
    "# Load in the three text files for each source, join all the table information together and save\n",
    "# Only needs to be done once\n",
    "\n",
    "for source in source_list:\n",
    "\n",
    "    LofarLR = pd.read_csv(RLF.LLR %source, header = 0)\n",
    "    RidgeLR = pd.read_csv(RLF.RLR %source, header = 0, usecols = ['Ridge_LR'])\n",
    "    MagCutOut = pd.read_csv(RLF.MagCO %source, header = 0, usecols = [str(RLF.IDW), str(RLF.IDP), str(RLF.PossRA), str(RLF.OptMagA), str(RLF.OptMagP)])\n",
    "    MagCutOut[str(RLF.PossRA)] = MagCutOut[str(RLF.PossRA)].apply(lambda x: round(x, 7))\n",
    "            \n",
    "    All_LR = LofarLR.join(RidgeLR['Ridge_LR'])\n",
    "    # Changed combined to use just the lofar value if the ridge value is nan\n",
    "    All_LR['Multi_LR'] = np.where(~np.isnan(All_LR['Ridge_LR']), All_LR['Lofar_LR'].astype(np.float64).multiply(All_LR['Ridge_LR'].astype(np.float64), axis = 'index'), All_LR['Lofar_LR'].astype(np.float64))\n",
    "        \n",
    "    All_LR.columns=['LofarRDis', 'Lofar_LR', str(RLF.PossRA), str(RLF.PossDEC), 'Ridge_LR', 'Multi_LR']\n",
    "    All_LR[str(RLF.PossRA)] = All_LR[str(RLF.PossRA)].apply(lambda x: round(x, 7))\n",
    "            \n",
    "    MagLR = All_LR.merge(MCO, on = str(RLF.PossRA))\n",
    "            \n",
    "    MagLR.to_csv(RLF.LRI %source, columns = ['LofarRDis', 'Lofar_LR', str(RLF.PossRA), str(RLF.PossDEC), 'Ridge_LR', 'Multi_LR', str(RLF.IDW), str(RLF.IDP), str(RLF.OptMagP), str(RLF.OptMagA)], header = True, index = False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load in Host Info\n",
    "Hosts = pd.read_csv(str(RLF.DR1Hosts), usecols = [ 'Source_Name', 'AllWISE', 'Host_RA', 'Host_DEC', 'W1mag', 'i'], header = 0)\n",
    "Hosts['Colour'] = Hosts['i'].astype(np.float64).subtract(Hosts['W1mag'].astype(np.float64), axis = 'index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the colour column and sample the df\n",
    "pwfulldf = pd.read_csv(RLF.OptCatdf, header = 0, usecols = ['AllWISE', 'i', 'W1mag'])\n",
    "ColourPW = pwfulldf[~np.isnan(pwfulldf['i']) & ~np.isnan(pwfulldf['W1mag'])].copy()\n",
    "ColourPW.reset_index(drop = True, inplace = True)\n",
    "\n",
    "ColourPW['Colour'] = ColourPW['i'].subtract(ColourPW['W1mag'], axis = 'index')\n",
    "ColSam = ColourPW.sample(50000, replace = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11431476680.687202\n"
     ]
    }
   ],
   "source": [
    "# Skyarea Covered byt he LOFAR data set\n",
    "area = (np.deg2rad(RLC.LRAu) - np.deg2rad(RLC.LRAd)) * (np.sin(np.deg2rad(RLC.LDECu)) - np.sin(np.deg2rad(RLC.LDECd))) * np.rad2deg(3600)**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Not running on i-band so only need the W1 band cells\n",
    "hh, ww1 = np.mgrid[Hosts['Colour'].min() : Hosts['Colour'].max() : 0.05, Hosts['W1mag'].min() : Hosts['W1mag'].max() : 0.05]\n",
    "h_sample = np.vstack([ww1.ravel(), hh.ravel()]).T\n",
    "h_train = np.vstack([Hosts['W1mag'], Hosts['Colour']]).T\n",
    "kde_h = KernelDensity(kernel = 'gaussian', bandwidth = RLC.bw)\n",
    "kde_h.fit(h_train)\n",
    "prob_h = np.exp(kde_h.score_samples(h_sample))\n",
    "norm_h = len(Hosts['W1mag'])/np.sum(prob_h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "oo, ww2 = np.mgrid[ColSam['Colour'].min() : ColSam['Colour'].max() : 0.05, ColSam['W1mag'].min() : ColSam['W1mag'].max() : 0.05]\n",
    "o_sample = np.vstack([ww2.ravel(), oo.ravel()]).T\n",
    "o_train = np.vstack([ColSam['W1mag'], ColSam['Colour']]).T\n",
    "kde_o = KernelDensity(kernel = 'gaussian', bandwidth = RLC.bw)\n",
    "kde_o.fit(o_train)\n",
    "prob_o = np.exp(kde_o.score_samples(o_sample))\n",
    "norm_o = len(ColSam['W1mag'])/np.sum(prob_o) * area"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# functions needed\n",
    "\n",
    "def GetLR(fr, qm, nm):\n",
    "    lr = (fr * qm) / nm\n",
    "    return lr\n",
    "\n",
    "def Getqmc(m, c):\n",
    "    qmc = np.exp(kde_h.score_samples(np.array([m, c]).reshape(1, -1)))\n",
    "    return qmc * norm_h\n",
    "\n",
    "def Getnmc(m, c):\n",
    "    nmc = np.exp(kde_o.score_samples(np.array([m, c]).reshape(1, -1)))\n",
    "    return nmc * norm_o"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculating the LR from the text files for the W1 band hosts\n",
    "\n",
    "# Removed the line where you deal with taking the W1 value if the r band value was 0.\n",
    "\n",
    "for source in source_list:\n",
    "            \n",
    "    #MLRhw = pd.read_csv(str(RLF.NLRI) %source, header = 0, usecols = ['AllWise', 'LofarRDis', 'ra', 'dec', 'Lofar_LR', 'Ridge_LR', 'SBLR', 'Multi_LR',  'i', 'W1mag'])\n",
    "    MLR = pd.read_csv(str(RLF.LRI) %source, header = 0, usecols = ['LofarRDis', str(RLF.PossRA), str(RLF.PossDEC), str(RLF.IDW), str(RLF.IDP), str(RLF.OptMagP), str(RLF.OptMagA), 'Multi_LR'])\n",
    "    MLR['Colour'] = MLR['i'].subtract(MLR['W1mag'], axis = 'index')\n",
    "    MCLR = MLR[~np.isnan(MLR['Colour'])].copy()\n",
    "    #MCLR['MCLLR'] = MCLR.apply(lambda row: GetLR(row['Lofar_LR'], Getqmc(row['W1mag'], row['Colour']), Getnmc(row['W1mag'], row['Colour'])), axis = 1).astype(np.float128)\n",
    "    #MCLR['MCRLR'] = MCLR.apply(lambda row: GetLR(row['Ridge_LR'], Getqmc(row['W1mag'], row['Colour']), Getnmc(row['W1mag'], row['Colour'])), axis = 1).astype(np.float128)\n",
    "    #MCLRhw['MCSBLR'] = MCLRhw.apply(lambda row: GetLR(row['SBLR'], Getqmcw(row['W1mag'], row['Colour']), Getnmcw(row['W1mag'], row['Colour'])), axis = 1).astype(np.float128)\n",
    "    MCLR[str(RLF.LRMC)] = MCLR.apply(lambda row: GetLR(row['Multi_LR'], Getqmc(row['W1mag'], row['Colour']), Getnmc(row['W1mag'], row['Colour'])), axis = 1).astype(np.float128)\n",
    "            \n",
    "    #MCLRhw.to_csv(str(RLF.MCLR) %source, columns = ['AllWise', 'LofarRDis', 'ra', 'dec', 'Lofar_LR', 'Ridge_LR', 'SBLR', 'Multi_LR',  'i', 'W1mag', 'MCLLR', 'MCRLR', 'MCSBLR', 'MCMLR'], header = True, index = False)\n",
    "    MCLR.to_csv(str(RLF.LR) %source, columns = ['LofarRDis', str(RLF.PossRA), str(RLF.PossDEC), str(RLF.IDW), str(RLF.IDP), str(RLF.OptMagP), str(RLF.OptMagA), str(RLF.LRMC)], header = True, index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For each source in the list find the maximum combined LR and store all the information\n",
    "\n",
    "def FindMax(source):\n",
    "    info = pd.read_csv(RLF.LR %source, header = 0, usecols = [str(RLF.PossRA), str(RLF.PossDEC), str(RLF.IDW), str(RLF.IDP), str(RLF.LRMC)])\n",
    "    info[str(RLF.IDW)] = info[str(RLF.IDW)].map(lambda x: x.strip('b').strip(\"''\"))\n",
    "    info[str(RLF.IDP)] = info[str(RLF.IDP)].map(lambda x: x.strip('b').strip(\"''\"))\n",
    "    #info[str(RLF.ID3)] = info[str(RLF.ID3)].map(lambda x: x.strip('b').strip(\"''\"))\n",
    "    CP = info.loc[info[str(RLF.LRMC)].idxmax()].copy()\n",
    "    CP['PossFail'] = np.where(CP[str(RLF.LRMC)] < RLC.Lth, 1, 0)\n",
    "    CP[str(RLF.LSN)] = source\n",
    "    \n",
    "    return CP\n",
    "\n",
    "PossHosts = pd.concat([FindMax(source) for source in source_list], ignore_index = True, axis = 1)\n",
    "PossHosts.columns = PossHosts.loc[str(RLF.LSN)]\n",
    "PossHosts = PossHosts.drop(index = [str(RLF.LRMC), str(RLF.LSN)])\n",
    "PossHostsT = PossHosts.transpose()\n",
    "PossHostsT.to_csv(RLF.PossHosts, header = True, index = True)#,  columns = [str(RLF.LSN), str(RLF.PossRA), str(RLF.PossDEC), str(RLF.IDW), str(RLF.IDP), str(RLF.ID3), str(RLF.OptMagP), str(RLF.OptMagA)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of sources with a 0 max LR and therefore would possibly be a failed LR\n",
    "# or defined by being closest to LOFAR\n",
    "print(np.sum(PossHostsT['PossFail']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
